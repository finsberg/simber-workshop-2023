{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion estimation\n",
    "\n",
    "In this section we will go through how to perform motion analysis on MPS data. The material here is mostly based on the documentation at https://computationalphysiology.github.io/mps_motion\n",
    "\n",
    "First we need to import `mps` for reading the data and `mps_motion` for performing motion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path # For working with file paths\n",
    "import mps  # For reading MPS data\n",
    "import mps_motion # For motion estimation\n",
    "import matplotlib.pyplot as plt # For plotting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "motion_data_path = Path(\"motion_data.npy\")\n",
    "\n",
    "def download_data():\n",
    "    print(\"Downloading data. Please wait...\")\n",
    "    link = \"https://www.dropbox.com/s/kh6jlvyjyxpcea3/motion_data.npy?dl=1\"\n",
    "    import urllib.request\n",
    "    import time\n",
    "\n",
    "    urllib.request.urlretrieve(link, motion_data_path)\n",
    "    time.sleep(1.0)\n",
    "    print(\"Done downloading data\")\n",
    "    \n",
    "if not motion_data_path.is_file():\n",
    "    download_data()\n",
    "    \n",
    "data = mps.MPS(motion_data_path)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let us first print some info about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in particular that we have 0.65 micro meter per pixel. This mean that the physical width and height of one pixel is 0.65 micrometer. This information will be important when converting the displacment and velocity to real units.\n",
    "\n",
    "We can also display convert the frames to a video file that we can play in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_path = \"motion_data.mp4\"\n",
    "mps.utils.frames2mp4(data.frames.T, movie_path, framerate=data.framerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(movie_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displacement and velocity\n",
    "\n",
    "We will discuss two different measures of motion, namely the velocity and the displacement. These things are tightly related. \n",
    "\n",
    "We will refer to the *displacement* as the motion from one specific reference image. In other words, we define one image in the recording as the reference image and for all the other images, we compute the motion from this reference image to every othere image. \n",
    "\n",
    "The *velocity* on the other had has reference image that depends on the current image, so that the velocity at a given point in time is defined as the motion from a previous image with a fixed number of images before it. We will refer to this number as the spacing. For example, we could choose a spacing of 5, in which case the velocity at a given point will be the motion of the image five timepoints before it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating optical flow object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting we will create an optical flow object which is the object we use to run the motion tracking software. Here we have chosen the Farneback optical flow algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_flow = mps_motion.OpticalFlow(data, flow_algorithm=\"farneback\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list available optical flow algorithms you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mps_motion.list_optical_flow_algorithm()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the velocity and reference frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run the motion analysis we need to estimate a suitable reference frame. We can do this by first estimate the velocity (let us use a spacing of 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spacing = 5\n",
    "v = opt_flow.get_velocities(spacing=spacing)\n",
    "print(v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the object we get back is a `VectorFrameSequence`. This is a special object that represents a vector field for each image in the sequence of images, and we see that is has dimension (number of pixels in $\\times$ number of pixels in $\\times$ number of time steps  2) where the final two dimensions are the and component of the vectors. The default units of time is milliseconds, so velocity has units micrometer per miliseconds. Let us convert this to micro meter per seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v *= 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the velocity norm and average over the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_norm_mean = v.norm().mean().compute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we need to also call `compute()` on the object. This is becase the compuation will be executed in paralell. \n",
    "\n",
    "Let us now use the velocity to estimate the reference frame. This algorithm will use the the zero velocity baseline a find a frame where the velocity is zero. We must also provide the time stamps with the same length as the velocity trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_frame_index = (\n",
    "    mps_motion.motion_tracking.estimate_referece_image_from_velocity(\n",
    "        t=data.time_stamps[:-spacing],\n",
    "        v=v_norm_mean,\n",
    "    )\n",
    ")\n",
    "reference_frame = data.time_stamps[reference_frame_index]\n",
    "print(f\"Found reference frame at index {reference_frame_index} and time {reference_frame:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also plot the velocity trace and mark the point where the reference frame is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(data.time_stamps[:-spacing], v_norm_mean)\n",
    "ax.plot([reference_frame], [v_norm_mean[reference_frame_index]], \"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try to use a different spacing and see how this changes the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing displacement\n",
    "\n",
    "We can now run the optical flow algorithm to extract the displacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u = opt_flow.get_displacements(reference_frame=reference_frame)\n",
    "print(u)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the velocity, the displacment is a `VectorFrameSequence`. If we take the norm of this VectorFrameSequence we get a `FrameSequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_norm = u.norm()\n",
    "u_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stead of being a `VectorFrameSequence` we now have a `FrameSequence`, so that for each value represents the norm of the vector from the `VectorFrameSequence`.\n",
    "\n",
    "We can for example compute the maximum norm over all time steps by calling `.max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_norm_max = u_norm.max().compute()\n",
    "print(u_norm_max.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the shape of this array is the same shape as each image. And the values at each pixel will be the maximum displacment over all time points. We can plot this as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(u_norm_max.T)\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.set_label(\"Maximum displacement [\\u00B5m]\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image will highlight regions with high displacement, and we could use it to identify the pixels with cells.\n",
    "\n",
    "Similar to velocity, we can also compute the mean over the entire image, in order to reduce each image down to a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_norm_mean = u_norm.mean().compute()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data.time_stamps, u_norm_mean)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you might notice is that the maximum average displacement is much lower than the maximum displacement at all pixels which was closer to 5 micro meters\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Try to use a different reference index (i.e not the one estimated) and see how this changes the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Features\n",
    "\n",
    "Let us now extract one beat and compute some simple feaures of the displacement and velocity. \n",
    "\n",
    "We have created a little utility function for plotting these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import plot_features\n",
    "\n",
    "fig, ax = plot_features(u_norm=u_norm_mean, v_norm=v_norm_mean, time=data.time_stamps)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute these features for the three beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = mps_motion.stats.compute_features(u=u_norm_mean, v=v_norm_mean, t=data.time_stamps)\n",
    "for key, values in features.items():\n",
    "    print(key, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
